\chapter{A féléves munka rövid áttekintése}

\section{Elméleti áttekintés}

A feladatom az volt, hogy az 5G OFDMA rendszerek szinkronizációs eljárásait vizsgáljam implementációs oldalról. 
Erre azért van szükség, mert a rendszert leíró szabványok csak a szinkronizációs fejléceket specifikálják, azt, hogy milyen a BS-ek által sugárzott szinkronizációs jelek, hogy hordozzák a megfelelő információt, azt már nem, hogy ezeket hogyan dekódolhatjuk UE oldalról.

Bár ez egy ideális esetben nem okoz problémát, a valóságban ezeket a jelátviteleket különböző frekvencia- és időhibák terhelik.
Előbbi származhat az eszközök egymáshoz viszonyított mozgásából a Doppler hatásnak megfelelően, vagy a készülékek helyi oszcillátorából (ez jellemzően egy nagyobb hibát eredményez, ezért a munkámban ezt veszem figyelembe), míg utóbbi csupán abból származik, hogy a telefont nem tudjuk az OFDMA rendszerünkön belül értelmezett $ t = 0 $ időpillanatban bekapcsolni.

A készülék helyi oszcillátorának frekvenciahibáját megadhatjuk abszolút értékben ($ \Delta f = 15 \text{ Hz}$), megadhatjuk egy relatív egységben ($\Delta f = 50 \text{ ppm}$ - parts per million = $10^{-6}$) vagy normalizált egységben is, amely azt jelenti, hogy a frekvenciahibát az alvivő távolsághoz viszonyítva adjuk meg.

\chapter{5G szinkronizációs lépések}

\section{Első lépés}

Tekintsük az alapállapotot. Ilyenkor minden kapcsolat stabil. Minden felhasználói készülék (User Equipment - UE) tudja, hogy milyen frekvenciacsoportban kommunikál melyik alállomással (bázisállomás). A készülékek nem mozognak, handover nem történik, gyakorlatilag semmi nem történik.
Ebben az állapotban kapcsolunk be egy telefont. A bekapcsoló telefon értelemszerűen elkezdi keresni a hálózatot, hogy létrejöhessen a kapcsolat, de egy 5G rendszerben nagyon sok frekvencián jöhet létre a rádiós kapcsolat, ezért ez nem olyan egyszerű. 